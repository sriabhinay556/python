import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

er=[]
m1=[]
c1=[]
te=[]
def compute_error(c, m, x,y):
    totalError = 0
    x = x
    y = y
    #print(c,m)
    m1.append(m)
    c1.append(c)
    for i in range(0,len(x)):
        totalError+=(((m * x[i] + c)-y[i]) ** 2)
      #te.append(totalError)
    #print(te)
    #err=(np.array(te).sum())
    er.append(totalError/len(x))
    #print(er)

def step_gradient(c_current, m_current, x,y, learningRate):
    c_gradient = 0.0
    m_gradient = 0.0
    N = float(len(x))
    x = x
    y = y
    cg=[]
    mg=[]
    for i in range(0,len(x)):
        cg.append(((m_current * x[i]) + c_current)-y[i])
        mg.append(x[i] * (((m_current * x) + c_current)-y[i]))
    c_gradient=(np.array(cg).sum())/N
    m_gradient=(np.array(mg).sum())/N
    new_c = c_current - (learningRate * c_gradient)
    new_m = m_current - (learningRate * m_gradient)
    compute_error(new_c,new_m,x,y)
    return [new_c, new_m]
    def gradient_descent_runner(x,y, starting_c, starting_m, learning_rate, num_iterations):
    c = starting_c
    m = starting_m
    for i in range(num_iterations):
        c,m=step_gradient(c, m, x,y, learning_rate)
      #print(c,m)
   
def run():
    sn = pd.read_csv('Salary_Data.csv')
    x1=sn.iloc[:,0:1]
    y1=sn.iloc[:,1:2]
    x=np.array(x1)
    y=np.array(y1)
    learning_rate = 0.001
    initial_c = 1 # initial y-intercept guess
    initial_m = 1 # initial slope guess
    num_iterations = 100
    compute_error(initial_c, initial_m,x,y)
    gradient_descent_runner(x,y, initial_c, initial_m, learning_rate, num_iterations)
    


run()
it=np.arange(0,101)
